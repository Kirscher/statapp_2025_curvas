
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-17 17:44:25.018811: do_dummy_2d_data_aug: False 
2025-02-17 17:44:25.019373: Creating new 5-fold cross-validation split... 
2025-02-17 17:44:25.020476: Desired fold for training: 0 
2025-02-17 17:44:25.020544: This split has 16 training and 4 validation cases. 
2025-02-17 17:44:48.199383: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [192, 112, 112], 'median_image_size_in_voxels': [943.0, 512.0, 512.0], 'spacing': [1.0, 0.9626015722751617, 0.9626015722751617], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset475_CURVAS', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 0.9626015722751617, 0.9626015722751617], 'original_median_shape_after_transp': [956, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 901.9999389648438, 'mean': 116.67008209228516, 'median': 113.99999237060547, 'min': -1036.0001220703125, 'percentile_00_5': -34.99999237060547, 'percentile_99_5': 255.0, 'std': 43.83061599731445}}} 
 
2025-02-17 17:44:50.241830: unpacking dataset... 
2025-02-17 17:45:22.210190: unpacking done... 
2025-02-17 17:45:22.215066: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-02-17 17:45:22.226229:  
2025-02-17 17:45:22.226337: Epoch 0 
2025-02-17 17:45:22.226614: Current learning rate: 0.01 
2025-02-17 17:51:14.377482: train_loss 0.141 
2025-02-17 17:51:14.377962: val_loss -0.0265 
2025-02-17 17:51:14.378066: Pseudo dice [np.float32(0.0), np.float32(0.3739), np.float32(0.7692)] 
2025-02-17 17:51:14.378305: Epoch time: 352.15 s 
2025-02-17 17:51:14.378377: Yayy! New best EMA pseudo Dice: 0.38100001215934753 
2025-02-17 17:51:17.172619:  
2025-02-17 17:51:17.172990: Epoch 1 
2025-02-17 17:51:17.173129: Current learning rate: 0.00999 
2025-02-17 17:55:43.247313: train_loss -0.0098 
2025-02-17 17:55:43.247720: val_loss -0.0941 
2025-02-17 17:55:43.247797: Pseudo dice [np.float32(0.0), np.float32(0.4459), np.float32(0.8054)] 
2025-02-17 17:55:43.247884: Epoch time: 266.08 s 
2025-02-17 17:55:43.247956: Yayy! New best EMA pseudo Dice: 0.3846000134944916 
2025-02-17 17:55:45.428087:  
2025-02-17 17:55:45.428479: Epoch 2 
2025-02-17 17:55:45.428610: Current learning rate: 0.00998 
2025-02-17 18:00:11.392231: train_loss -0.1085 
2025-02-17 18:00:11.392657: val_loss -0.1774 
2025-02-17 18:00:11.392752: Pseudo dice [np.float32(0.0), np.float32(0.5397), np.float32(0.8576)] 
2025-02-17 18:00:11.392846: Epoch time: 265.97 s 
2025-02-17 18:00:11.392920: Yayy! New best EMA pseudo Dice: 0.3928000032901764 
2025-02-17 18:00:14.501819:  
2025-02-17 18:00:14.502072: Epoch 3 
2025-02-17 18:00:14.502203: Current learning rate: 0.00997 
2025-02-17 18:04:40.620443: train_loss -0.1652 
2025-02-17 18:04:40.620790: val_loss -0.2543 
2025-02-17 18:04:40.620870: Pseudo dice [np.float32(0.3394), np.float32(0.6955), np.float32(0.8435)] 
2025-02-17 18:04:40.620958: Epoch time: 266.12 s 
2025-02-17 18:04:40.621018: Yayy! New best EMA pseudo Dice: 0.41609999537467957 
2025-02-17 18:04:42.882613:  
2025-02-17 18:04:42.882974: Epoch 4 
2025-02-17 18:04:42.883088: Current learning rate: 0.00996 
2025-02-17 18:09:08.916087: train_loss -0.2722 
2025-02-17 18:09:08.918837: val_loss -0.3416 
2025-02-17 18:09:08.918997: Pseudo dice [np.float32(0.4466), np.float32(0.7509), np.float32(0.8734)] 
2025-02-17 18:09:08.919108: Epoch time: 266.03 s 
2025-02-17 18:09:08.919178: Yayy! New best EMA pseudo Dice: 0.44350001215934753 
2025-02-17 18:09:11.451868:  
2025-02-17 18:09:11.452152: Epoch 5 
2025-02-17 18:09:11.452300: Current learning rate: 0.00995 
2025-02-17 18:13:37.443296: train_loss -0.3054 
2025-02-17 18:13:37.443606: val_loss -0.3802 
2025-02-17 18:13:37.443709: Pseudo dice [np.float32(0.5159), np.float32(0.856), np.float32(0.8884)] 
2025-02-17 18:13:37.443988: Epoch time: 265.99 s 
2025-02-17 18:13:37.444050: Yayy! New best EMA pseudo Dice: 0.47450000047683716 
2025-02-17 18:13:39.801326:  
2025-02-17 18:13:39.801720: Epoch 6 
2025-02-17 18:13:39.801861: Current learning rate: 0.00995 
2025-02-17 18:18:05.858195: train_loss -0.3285 
2025-02-17 18:18:05.858536: val_loss -0.3968 
2025-02-17 18:18:05.858619: Pseudo dice [np.float32(0.5291), np.float32(0.8607), np.float32(0.8754)] 
2025-02-17 18:18:05.858706: Epoch time: 266.06 s 
2025-02-17 18:18:05.858761: Yayy! New best EMA pseudo Dice: 0.5026000142097473 
2025-02-17 18:18:08.073787:  
2025-02-17 18:18:08.074333: Epoch 7 
2025-02-17 18:18:08.074469: Current learning rate: 0.00994 
2025-02-17 18:22:34.021424: train_loss -0.3806 
2025-02-17 18:22:34.021853: val_loss -0.3582 
2025-02-17 18:22:34.021950: Pseudo dice [np.float32(0.504), np.float32(0.8278), np.float32(0.8328)] 
2025-02-17 18:22:34.022051: Epoch time: 265.95 s 
2025-02-17 18:22:34.022119: Yayy! New best EMA pseudo Dice: 0.5245000123977661 
2025-02-17 18:22:36.264971:  
2025-02-17 18:22:36.265415: Epoch 8 
2025-02-17 18:22:36.265550: Current learning rate: 0.00993 
2025-02-17 18:27:02.260711: train_loss -0.3816 
2025-02-17 18:27:02.261131: val_loss -0.2835 
2025-02-17 18:27:02.261228: Pseudo dice [np.float32(0.4693), np.float32(0.82), np.float32(0.8104)] 
2025-02-17 18:27:02.261327: Epoch time: 266.0 s 
2025-02-17 18:27:02.261396: Yayy! New best EMA pseudo Dice: 0.5419999957084656 
2025-02-17 18:27:04.701573:  
2025-02-17 18:27:04.701859: Epoch 9 
2025-02-17 18:27:04.701988: Current learning rate: 0.00992 
2025-02-17 18:31:30.755485: train_loss -0.3663 
2025-02-17 18:31:30.755810: val_loss -0.4666 
2025-02-17 18:31:30.755903: Pseudo dice [np.float32(0.6395), np.float32(0.8838), np.float32(0.8792)] 
2025-02-17 18:31:30.756043: Epoch time: 266.06 s 
2025-02-17 18:31:30.756171: Yayy! New best EMA pseudo Dice: 0.5679000020027161 
2025-02-17 18:31:33.094138:  
2025-02-17 18:31:33.094367: Epoch 10 
2025-02-17 18:31:33.094496: Current learning rate: 0.00991 
2025-02-17 18:35:59.137959: train_loss -0.4371 
2025-02-17 18:35:59.138251: val_loss -0.4299 
2025-02-17 18:35:59.138327: Pseudo dice [np.float32(0.5685), np.float32(0.9098), np.float32(0.9149)] 
2025-02-17 18:35:59.138408: Epoch time: 266.05 s 
2025-02-17 18:35:59.138468: Yayy! New best EMA pseudo Dice: 0.5909000039100647 
2025-02-17 18:36:01.220469:  
2025-02-17 18:36:01.220818: Epoch 11 
2025-02-17 18:36:01.220947: Current learning rate: 0.0099 
2025-02-17 18:40:27.237038: train_loss -0.4521 
2025-02-17 18:40:27.237388: val_loss -0.4962 
2025-02-17 18:40:27.237486: Pseudo dice [np.float32(0.6417), np.float32(0.8958), np.float32(0.8964)] 
2025-02-17 18:40:27.237584: Epoch time: 266.02 s 
2025-02-17 18:40:27.237652: Yayy! New best EMA pseudo Dice: 0.6129000186920166 
2025-02-17 18:40:29.627173:  
2025-02-17 18:40:29.627517: Epoch 12 
2025-02-17 18:40:29.627647: Current learning rate: 0.00989 
2025-02-17 18:44:55.234515: train_loss -0.4493 
2025-02-17 18:44:55.237993: val_loss -0.4542 
2025-02-17 18:44:55.238113: Pseudo dice [np.float32(0.6322), np.float32(0.9283), np.float32(0.8798)] 
2025-02-17 18:44:55.238201: Epoch time: 265.61 s 
2025-02-17 18:44:55.238256: Yayy! New best EMA pseudo Dice: 0.6330000162124634 
2025-02-17 18:44:57.586141:  
2025-02-17 18:44:57.586461: Epoch 13 
2025-02-17 18:44:57.586597: Current learning rate: 0.00988 
2025-02-17 18:49:22.690251: train_loss -0.4473 
2025-02-17 18:49:22.690669: val_loss -0.4754 
2025-02-17 18:49:22.690767: Pseudo dice [np.float32(0.5971), np.float32(0.9292), np.float32(0.8895)] 
2025-02-17 18:49:22.690868: Epoch time: 265.11 s 
2025-02-17 18:49:22.690938: Yayy! New best EMA pseudo Dice: 0.6502000093460083 
2025-02-17 18:49:24.927548:  
2025-02-17 18:49:24.927878: Epoch 14 
2025-02-17 18:49:24.928006: Current learning rate: 0.00987 
2025-02-17 18:53:50.330538: train_loss -0.4704 
2025-02-17 18:53:50.330843: val_loss -0.4964 
2025-02-17 18:53:50.330946: Pseudo dice [np.float32(0.633), np.float32(0.9376), np.float32(0.886)] 
2025-02-17 18:53:50.331043: Epoch time: 265.4 s 
2025-02-17 18:53:50.331098: Yayy! New best EMA pseudo Dice: 0.6671000123023987 
2025-02-17 18:53:52.176976:  
2025-02-17 18:53:52.177171: Epoch 15 
2025-02-17 18:53:52.177340: Current learning rate: 0.00986 
2025-02-17 18:58:17.783351: train_loss -0.4859 
2025-02-17 18:58:17.783591: val_loss -0.5118 
2025-02-17 18:58:17.783663: Pseudo dice [np.float32(0.5769), np.float32(0.9298), np.float32(0.9172)] 
2025-02-17 18:58:17.783746: Epoch time: 265.61 s 
2025-02-17 18:58:17.783798: Yayy! New best EMA pseudo Dice: 0.6812000274658203 
2025-02-17 18:58:20.624924:  
2025-02-17 18:58:20.625240: Epoch 16 
2025-02-17 18:58:20.625430: Current learning rate: 0.00986 
2025-02-17 19:02:46.538442: train_loss -0.4985 
2025-02-17 19:02:46.538868: val_loss -0.5424 
2025-02-17 19:02:46.538950: Pseudo dice [np.float32(0.6611), np.float32(0.8996), np.float32(0.9261)] 
2025-02-17 19:02:46.539035: Epoch time: 265.91 s 
2025-02-17 19:02:46.539088: Yayy! New best EMA pseudo Dice: 0.695900022983551 
2025-02-17 19:02:48.711359:  
2025-02-17 19:02:48.711700: Epoch 17 
2025-02-17 19:02:48.711834: Current learning rate: 0.00985 
2025-02-17 19:07:14.637323: train_loss -0.4678 
2025-02-17 19:07:14.637570: val_loss -0.4958 
2025-02-17 19:07:14.637646: Pseudo dice [np.float32(0.6917), np.float32(0.889), np.float32(0.9224)] 
2025-02-17 19:07:14.637725: Epoch time: 265.93 s 
2025-02-17 19:07:14.637777: Yayy! New best EMA pseudo Dice: 0.7098000049591064 
2025-02-17 19:07:16.824301:  
2025-02-17 19:07:16.824849: Epoch 18 
2025-02-17 19:07:16.824988: Current learning rate: 0.00984 
2025-02-17 19:11:42.738951: train_loss -0.4891 
2025-02-17 19:11:42.739222: val_loss -0.4834 
2025-02-17 19:11:42.739299: Pseudo dice [np.float32(0.6487), np.float32(0.9157), np.float32(0.8561)] 
2025-02-17 19:11:42.739380: Epoch time: 265.92 s 
2025-02-17 19:11:42.739435: Yayy! New best EMA pseudo Dice: 0.7195000052452087 
2025-02-17 19:11:44.841548:  
2025-02-17 19:11:44.841772: Epoch 19 
2025-02-17 19:11:44.842003: Current learning rate: 0.00983 
2025-02-17 19:16:10.840020: train_loss -0.5392 
2025-02-17 19:16:10.840419: val_loss -0.5053 
2025-02-17 19:16:10.840543: Pseudo dice [np.float32(0.741), np.float32(0.9286), np.float32(0.8841)] 
2025-02-17 19:16:10.840647: Epoch time: 266.0 s 
2025-02-17 19:16:10.840719: Yayy! New best EMA pseudo Dice: 0.732699990272522 
2025-02-17 19:16:13.390811:  
2025-02-17 19:16:13.391326: Epoch 20 
2025-02-17 19:16:13.391561: Current learning rate: 0.00982 
2025-02-17 19:20:39.414970: train_loss -0.5285 
2025-02-17 19:20:39.415269: val_loss -0.55 
2025-02-17 19:20:39.415370: Pseudo dice [np.float32(0.7541), np.float32(0.932), np.float32(0.9286)] 
2025-02-17 19:20:39.415473: Epoch time: 266.03 s 
2025-02-17 19:20:39.415618: Yayy! New best EMA pseudo Dice: 0.7465000152587891 
2025-02-17 19:20:41.770352:  
2025-02-17 19:20:41.770582: Epoch 21 
2025-02-17 19:20:41.770709: Current learning rate: 0.00981 
2025-02-17 19:25:07.886434: train_loss -0.4975 
2025-02-17 19:25:07.886843: val_loss -0.5461 
2025-02-17 19:25:07.886920: Pseudo dice [np.float32(0.7256), np.float32(0.9198), np.float32(0.9345)] 
2025-02-17 19:25:07.887002: Epoch time: 266.12 s 
2025-02-17 19:25:07.887057: Yayy! New best EMA pseudo Dice: 0.7578999996185303 
2025-02-17 19:25:09.968344:  
2025-02-17 19:25:09.968557: Epoch 22 
2025-02-17 19:25:09.968688: Current learning rate: 0.0098 

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (2.2.5)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/site-packages (1.15.2)\n",
      "Collecting monai\n",
      "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading setuptools-80.3.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch)\n",
      "  Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/site-packages (from torchmetrics) (24.2)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.0/865.0 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Downloading setuptools-80.3.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, mpmath, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, filelock, triton, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, lightning-utilities, nvidia-cusolver-cu12, torch, torchmetrics, monai\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.5━━━━━━\u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/25\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.5━━━━━━━━━━━━\u001b[0m \u001b[32m 6/25\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cublas-cu12]u12]2]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.5━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling numpy-2.2.5:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/25\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.5\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/25\u001b[0m [numpy]las-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [monai]m24/25\u001b[0m [monai]etrics]er-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.18.0 lightning-utilities-0.14.3 monai-1.4.0 mpmath-1.3.0 networkx-3.4.2 numpy-1.26.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 setuptools-80.3.1 sympy-1.14.0 torch-2.7.0 torchmetrics-1.7.1 triton-3.3.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install scikit-learn numpy torch scipy monai torchmetrics\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.stats import norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import AsDiscrete\n",
    "from scipy.integrate import quad\n",
    "from scipy.interpolate import interp1d\n",
    "from monai.transforms import CropForeground\n",
    "\n",
    "from torchmetrics.classification import MulticlassCalibrationError\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "'''\n",
    "Prepare the annotations and results to be processed\n",
    "'''\n",
    "\n",
    "def format_normalisation (result_file, prob_file, pancreas_file, kidney_file, liver_file, ct_file) :\n",
    "    \"\"\" \n",
    "    Adapts CT scans results to the right format (slice, X, Y)\n",
    "    \"\"\"\n",
    "    bin_pred = nib.load(result_file).get_fdata().astype(np.uint8) \n",
    "\n",
    "    #(slices, X, Y)\n",
    "    bin_pred = bin_pred.transpose(2, 0, 1)\n",
    "\n",
    "    prob_data = nib.load(prob_file).get_fdata()\n",
    "\n",
    "    #(classes, slices, X, Y)\n",
    "    prob_pred = prob_data.transpose(0, 3, 1, 2)\n",
    "\n",
    "    pancreas_conf = prob_pred[0] \n",
    "    kidney_conf = prob_pred[1]\n",
    "    liver_conf = prob_pred[2]\n",
    "    results = [bin_pred, pancreas_conf, kidney_conf, liver_conf]\n",
    "\n",
    "    #Pancreas ground truth\n",
    "    gt1 = nib.load(pancreas_file).get_fdata()\n",
    "\n",
    "    #(slices, X, Y)\n",
    "    gt1 = gt1.transpose(2, 0, 1)\n",
    "    \n",
    "    #Kidney ground truth\n",
    "    gt2 = nib.load(kidney_file).get_fdata()\n",
    "\n",
    "    #(slices, X, Y)\n",
    "    gt2 = gt2.transpose(2, 0, 1)\n",
    "    \n",
    "    #Liver ground truth\n",
    "    gt3 = nib.load(liver_file).get_fdata()\n",
    "\n",
    "    #(slices, X, Y)\n",
    "    gt3 = gt3.transpose(2, 0, 1)\n",
    "\n",
    "    annotations = [gt1, gt2, gt3]\n",
    "\n",
    "    #CT scan, unlabeled with the three organs\n",
    "    ct_image = nib.load(ct_file).get_fdata()\n",
    "\n",
    "    #(slices, X, Y)\n",
    "    ct_image = ct_image.transpose(2, 0, 1)\n",
    "\n",
    "\n",
    "\n",
    "    return ct_image, annotations, results\n",
    "\n",
    "def preprocess_results(ct_image, annotations, results):\n",
    "    \"\"\"\n",
    "    Preprocess the images, predictions and annotations in order to be evaluated.\n",
    "    It crops the foreground and applies the same crop to the rest of matrices.\n",
    "    This is done to save some memory and work with smaller matrices.\n",
    "    \n",
    "    ct_image: CT images of shape (slices, X, Y)\n",
    "    annotations: list containing the three ground truths [gt1, gt2, gt3]\n",
    "                 each gt has the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "                 each gt has the following shape (slices, X, Y)\n",
    "    results: list containing the results [binarized prediction, \n",
    "                                          pancreas_confidence,\n",
    "                                          kidney_confidence,\n",
    "                                          liver_confidence\n",
    "                                         ]\n",
    "            the binarized prediction the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "            each confidence has probabilistic values that range from 0 to 1\n",
    "     \n",
    "    @output cropped_annotations, cropped_results[0], cropped_results[1:]\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the CropForeground transform\n",
    "    cropper = CropForeground(select_fn=lambda x: x > 0)  # Assuming non-zero voxels are foreground\n",
    "\n",
    "    # Compute the cropping box based on the CT image\n",
    "    box_start, box_end = cropper.compute_bounding_box(ct_image)\n",
    "    \n",
    "    # Apply the cropping box to all annotations\n",
    "    cropped_annotations = [annotation[..., box_start[0]:box_end[0], box_start[1]:box_end[1]] for annotation in annotations]\n",
    "    cropped_results = [result[..., box_start[0]:box_end[0], box_start[1]:box_end[1]] for result in results]\n",
    "\n",
    "    return cropped_annotations, cropped_results[0], cropped_results[1:]\n",
    "\n",
    "\n",
    "'''\n",
    "Dice Score Evaluation\n",
    "'''\n",
    "\n",
    "def consensus_dice_score(groundtruth, bin_pred, prob_pred):\n",
    "    \"\"\"\n",
    "    Computes an average of dice score for consensus areas only.\n",
    "    \n",
    "    groundtruth: numpy stack list containing the three ground truths [gt1, gt2, gt3]\n",
    "                 each gt has the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "                    (3, slices, X, Y)\n",
    "    bin_pred: binarized prediction matrix containing values: {0,1,2,3}\n",
    "    prob_pred: probability prediction matrix, shape: (3, slices, X, Y), the three being\n",
    "                a probability matrix per each class\n",
    "     \n",
    "    @output dice_scores, confidence\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform probability predictions to one-hot encoding by taking the argmax\n",
    "    prediction_onehot = AsDiscrete(to_onehot=4)(torch.from_numpy(np.expand_dims(bin_pred, axis=0)))[1:].astype(np.uint8)\n",
    "    \n",
    "    # Split ground truth into separate organs and calculate consensus\n",
    "    organs =  {1: 'panc', 2: 'kidn', 3: 'livr'}\n",
    "    consensus = {}\n",
    "    dissensus = {}\n",
    "\n",
    "    for organ_val, organ_name in organs.items():\n",
    "        # Get the ground truth for the current organ\n",
    "        organ_gt = (groundtruth == organ_val).astype(np.uint8)\n",
    "        organ_bck = (groundtruth != organ_val).astype(np.uint8)\n",
    "        \n",
    "        # Calculate consensus regions (all annotators agree)\n",
    "        consensus[organ_name] = np.logical_and.reduce(organ_gt, axis=0).astype(np.uint8)\n",
    "        consensus[f\"{organ_name}_bck\"] = np.logical_and.reduce(organ_bck, axis=0).astype(np.uint8)\n",
    "        \n",
    "        # Calculate dissensus regions (where both background and foreground are 0)\n",
    "        dissensus[organ_name] = np.logical_and(consensus[organ_name] == 0, \n",
    "                                               consensus[f\"{organ_name}_bck\"]== 0).astype(np.uint8)\n",
    "    \n",
    "    # Mask the predictions and ground truth with the consensus areas\n",
    "    predictions = {}\n",
    "    groundtruth_consensus = {}\n",
    "    confidence = {}\n",
    "\n",
    "    for organ_val, organ_name in organs.items():\n",
    "        # Apply the dissensus mask to exclude non-consensus areas\n",
    "        filtered_prediction = prediction_onehot[organ_val-1] * (1 - dissensus[organ_name])\n",
    "        filtered_groundtruth = consensus[organ_name] * (1 - dissensus[organ_name])\n",
    "        \n",
    "        predictions[organ_name] = filtered_prediction\n",
    "        groundtruth_consensus[organ_name] = filtered_groundtruth\n",
    "        \n",
    "        # Compute mean probabilities and confidence in the consensus area\n",
    "        prob_in_consensus_organ = prob_pred[organ_val-1] * np.where(consensus[organ_name]==1, 1, np.nan)\n",
    "        prob_in_consensus_bck = prob_pred[organ_val-1] * np.where(consensus[f\"{organ_name}_bck\"]==1, 1, np.nan)\n",
    "        mean_conf_organ = np.nanmean(prob_in_consensus_organ)\n",
    "        mean_conf_bck = np.nanmean(prob_in_consensus_bck)        \n",
    "        confidence[organ_name] = (((1-mean_conf_bck)+mean_conf_organ)/2)\n",
    "    \n",
    "    # Create DiceMetric instance\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False, ignore_empty=True)\n",
    "\n",
    "    dice_scores = {}\n",
    "    for organ_name in organs.values():\n",
    "        gt = torch.from_numpy(groundtruth_consensus[organ_name])\n",
    "        pred = torch.from_numpy(predictions[organ_name])\n",
    "        dice_metric.reset()\n",
    "        dice_metric(pred, gt)\n",
    "        dice_scores[organ_name] = dice_metric.aggregate().item()\n",
    "    \n",
    "    return dice_scores, confidence\n",
    "    \n",
    "\n",
    "'''\n",
    "Volume Assessment\n",
    "'''\n",
    "\n",
    "def volume_metric(groundtruth, prediction, voxel_proportion=1):\n",
    "    \"\"\"\n",
    "    Calculates the Continuous Ranked Probability Score (CRPS) for each volume class,\n",
    "    by using the ground truths to create a probabilistic distribution that keeps the\n",
    "    multirater information of having multiple annotations. \n",
    "    \n",
    "    groundtruth: numpy stack list containing the three ground truths [gt1, gt2, gt3]\n",
    "                 each gt has the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "                    (3, slices, X, Y)\n",
    "    prob_pred: probability prediction matrix, shape: (3, slices, X, Y), the three being\n",
    "                a probability matrix per each class\n",
    "    voxel_proportion: vaue of the resampling needed voxel-wise, 1 by default\n",
    "     \n",
    "    @output crps_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    cdf_list = calculate_volumes_distributions(groundtruth, voxel_proportion)\n",
    "        \n",
    "    crps_dict = {}    \n",
    "    organs =  {1: 'panc', 2: 'kidn', 3: 'livr'}\n",
    "\n",
    "    for organ_val, organ_name in organs.items():\n",
    "        probabilistic_volume = compute_probabilistic_volume(prediction[organ_val-1], voxel_proportion)\n",
    "        crps_dict[organ_name] = crps_computation(probabilistic_volume, cdf_list[organ_name], mean_gauss[organ_name], var_gauss[organ_name])\n",
    "\n",
    "    return crps_dict\n",
    "\n",
    "\n",
    "def heaviside(x):\n",
    "    return 0.5 * (np.sign(x) + 1)\n",
    "\n",
    "\n",
    "def crps_computation(predicted_volume, cdf, mean, std_dev):\n",
    "    \"\"\"\n",
    "    Calculates the Continuous Ranked Probability Score (CRPS) for each volume class,\n",
    "    by using the ground truths to create a probabilistic distribution that keeps the\n",
    "    multirater information of having multiple annotations. \n",
    "    \n",
    "    predicted_volume: scalar value representing the volume obtained from the \n",
    "                        probabilistic prediction\n",
    "    cdf: cumulative density distribution (CDF) of the groundtruth volumes\n",
    "    mean: mean of the gaussian distribution obtained from the three groundtruth volumes\n",
    "    std_dev: std_dev of the gaussian distribution obtained from the three groundtruth volumes\n",
    "     \n",
    "    @output crps_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    def integrand(y):\n",
    "        return (cdf(y) - heaviside(y - predicted_volume)) ** 2\n",
    "    \n",
    "    lower_limit = mean - 3 * std_dev\n",
    "    upper_limit = mean + 3 * std_dev\n",
    "    \n",
    "    crps_value, _ = quad(integrand, lower_limit, upper_limit)\n",
    "        \n",
    "    return crps_value\n",
    "\n",
    "\n",
    "def calculate_volumes_distributions(groundtruth, voxel_proportion=1):\n",
    "    \"\"\"\n",
    "    Calculates the Cumulative Distribution Function (CDF) of the Probabilistic Function Distribution (PDF)\n",
    "    obtained by calcuating the mean and the variance of considering the three annotations.\n",
    "    \n",
    "    groundtruth: numpy stack list containing the three ground truths [gt1, gt2, gt3]\n",
    "                 each gt has the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "                    (3, slices, X, Y)\n",
    "    voxel_proportion: vaue of the resampling needed voxel-wise, 1 by default\n",
    "    \n",
    "    @output cdfs_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    organs = {1: 'panc', 2: 'kidn', 3: 'livr'}\n",
    "    \n",
    "    global mean_gauss, var_gauss, volumes  # Make them global to access in crps\n",
    "    mean_gauss = {}\n",
    "    var_gauss = {}\n",
    "    volumes = {}\n",
    "\n",
    "    for organ_val, organ_name in organs.items():\n",
    "        volumes[organ_name] = [np.unique(gt, return_counts=True)[1][organ_val] * np.prod(voxel_proportion) for gt in groundtruth]\n",
    "        mean_gauss[organ_name] = np.mean(volumes[organ_name])\n",
    "        var_gauss[organ_name] = np.std(volumes[organ_name])\n",
    "\n",
    "    # Create normal distribution objects\n",
    "    gaussian_dists = {organ_name: norm(loc=mean_gauss[organ_name], scale=var_gauss[organ_name]) for organ_name in organs.values()}\n",
    "    \n",
    "    # Generate CDFs\n",
    "    cdfs = {}\n",
    "    for organ_name in organs.values():\n",
    "        x = np.linspace(gaussian_dists[organ_name].ppf(0.01), gaussian_dists[organ_name].ppf(0.99), 100)\n",
    "        cdf_values = gaussian_dists[organ_name].cdf(x)\n",
    "        cdfs[organ_name] = interp1d(x, cdf_values, bounds_error=False, fill_value=(0, 1))  # Create an interpolation function\n",
    "\n",
    "    return cdfs\n",
    "    \n",
    "    \n",
    "def compute_probabilistic_volume(preds, voxel_proportion=1):\n",
    "    \"\"\"\n",
    "    Computes the volume of the matrix given (either pancreas, kidney or liver)\n",
    "    by adding up all the probabilities in this matrix. This way the uncertainty plays\n",
    "    a role in the computation of the predicted organ. If there is no uncertainty, the \n",
    "    volume should be close to the mean obtained by averaging the three annotations.\n",
    "    \n",
    "    preds: probabilistic matrix of a specific organ\n",
    "    voxel_proportion: vaue of the resampling needed voxel-wise, 1 by default\n",
    "     \n",
    "    @output volume\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sum the predicted probabilities to get the volume\n",
    "    volume = preds.sum().item()\n",
    "    \n",
    "    return volume*voxel_proportion\n",
    "\n",
    "\n",
    "'''\n",
    "Expected Calibration Error\n",
    "'''\n",
    "\n",
    "def multirater_expected_calibration_error(annotations_list, prob_pred):\n",
    "    \"\"\"\n",
    "    Returns a list of length three of the Expected Calibration Error (ECE) per annotation.\n",
    "    \n",
    "    annotations_list: list of length three containing the three annotations\n",
    "    prob_pred: probability prediction matrix, shape: (3, slices, X, Y), the three being\n",
    "                a probability matrix per each class\n",
    "     \n",
    "    @output ece_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    ece_dict = {}\n",
    "\n",
    "    for e in range(3):\n",
    "        ece_dict[e] = expected_calibration_error(annotations_list[e], prob_pred)\n",
    "        \n",
    "    return ece_dict\n",
    "\n",
    "\n",
    "def expected_calibration_error(groundtruth, prob_pred_onehot, num_classes=4, n_bins=50):\n",
    "    \"\"\"\n",
    "    Computes the Expected Calibration Error (ECE) between the given annotation and the \n",
    "    probabilistic prediction\n",
    "    \n",
    "    groundtruth: groundtruth matrix containing the following values: 1: pancreas, 2: kidney, 3: liver\n",
    "                    shape: (slices, X, Y)\n",
    "    prob_pred_onehot: probability prediction matrix, shape: (3, slices, X, Y), the three being\n",
    "                    a probability matrix per each class\n",
    "    num_classes: number of classes\n",
    "    n_bins: number of bins                    \n",
    "                    \n",
    "    @output ece\n",
    "    \"\"\" \n",
    "    \n",
    "    # Convert inputs to torch tensors\n",
    "    all_groundtruth = torch.tensor(groundtruth)\n",
    "    all_samples = torch.tensor(prob_pred_onehot)\n",
    "    \n",
    "    # Calculate the probability for the background class\n",
    "    background_prob = 1 - all_samples.sum(dim=0, keepdim=True)\n",
    "    \n",
    "    # Combine background probabilities with the provided probabilities\n",
    "    all_samples_with_bg = torch.cat((background_prob, all_samples), dim=0)\n",
    "    \n",
    "    # Flatten the tensors to (num_samples, num_classes) and (num_samples,)\n",
    "    all_groundtruth_flat = all_groundtruth.view(-1)\n",
    "    all_samples_flat = all_samples_with_bg.permute(1, 2, 3, 0).reshape(-1, num_classes)\n",
    "    \n",
    "    # Initialize the calibration error metric\n",
    "    calibration_error = MulticlassCalibrationError(num_classes=num_classes, n_bins=n_bins)\n",
    "\n",
    "    # Calculate the ECE\n",
    "    ece = calibration_error(all_samples_flat, all_groundtruth_flat).cpu().detach().numpy().astype(np.float64)\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def prepare_inputs_for_ace(groundtruth, bin_pred, prob_pred):\n",
    "    background_prob = 1 - np.sum(prob_pred, axis=0, keepdims=True)\n",
    "    prob_pred_full = np.concatenate([background_prob, prob_pred], axis=0)\n",
    "\n",
    "    confids = np.max(prob_pred_full, axis=0)\n",
    "    flat_pred = bin_pred.flatten()\n",
    "    flat_gt = groundtruth.flatten()\n",
    "    flat_conf = confids.flatten()\n",
    "    correct = (flat_pred == flat_gt).astype(np.int32)\n",
    "\n",
    "    return correct, flat_conf\n",
    "\n",
    "def calib_stats(correct, calib_confids):\n",
    "    n_bins = 20\n",
    "    y_true = column_or_1d(correct)\n",
    "    y_prob = column_or_1d(calib_confids)\n",
    "\n",
    "    if y_prob.min() < 0 or y_prob.max() > 1:\n",
    "        raise ValueError(\"y_prob has values outside [0, 1]\")\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    if len(labels) > 2:\n",
    "        raise ValueError(f\"Only binary classification is supported. Provided labels {labels}.\")\n",
    "    y_true = label_binarize(y_true, classes=labels)[:, 0]\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0 + 1e-8, n_bins + 1)\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    nonzero = bin_total != 0\n",
    "    num_nonzero = len(nonzero[nonzero == True])\n",
    "    prob_true = bin_true[nonzero] / bin_total[nonzero]\n",
    "    prob_pred = bin_sums[nonzero] / bin_total[nonzero]\n",
    "\n",
    "    bin_discrepancies = np.abs(prob_true - prob_pred)\n",
    "    return bin_discrepancies, num_nonzero\n",
    "\n",
    "def calc_ace(correct, calib_confids):\n",
    "    bin_discrepancies, num_nonzero = calib_stats(correct, calib_confids)\n",
    "    return (1 / num_nonzero) * np.sum(bin_discrepancies)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_image, annotations, results = format_normalisation(\"path to prediction.nii.gz\", \"path to prediction_raw.nii.gz\", \"path to gt1\", \"path to gt2\", \"path to gt3\", \"path to ct_scan\")\n",
    "cropped_annotations, cropped_bin_pred, cropped_prob_pred = preprocess_results(ct_image, annotations, results)\n",
    "dice_scores, confidence = consensus_dice_score(cropped_annotations, cropped_bin_pred, cropped_prob_pred)\n",
    "ece_scores = multirater_expected_calibration_error(cropped_annotations, cropped_prob_pred)\n",
    "correct, calib_confids = prepare_inputs_for_ace(np.stack(annotations,axis=0), results[0], np.stack([results[1],results[2],results[3]]))\n",
    "ace_score = calc_ace(correct, calib_confids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nibabel'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m label_binarize\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnibabel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnib\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nibabel'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m img = \u001b[43mnib\u001b[49m.load(\u001b[33m'\u001b[39m\u001b[33mUKCHLL_001_000.nii.gz\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m data = img.get_fdata()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.shape) \n",
      "\u001b[31mNameError\u001b[39m: name 'nib' is not defined"
     ]
    }
   ],
   "source": [
    "img = nib.load('UKCHLL_001_000.nii.gz')\n",
    "\n",
    "data = img.get_fdata()\n",
    "\n",
    "print(data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16000000000000003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ils font juste nombre de ood trouvés/nb ood mais la manière dont est défini le OOD est peu claire et semble arbitraire'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUROC\n",
    "\"\"\" y_true=true labels et y_score= score d'incertitude\"\"\"\n",
    "y_true = [1,0,1,1,0,1,0,0,0,1]\n",
    "y_score = [0.1, 0.4, 0.35, 0.8, 0.7, 0.2, 0.9, 0.6, 0.8, 0.4]\n",
    "# courbe qui plot les nb de TP sur le nb de val positives (tx de vrai positifs) en fonction du nb de FP sur le nb de val négatives (tx de faux positifs)\n",
    "#ici utilise des probas --> on fixe un seuil à partir duquel un proba est considérée comme préd positive (par ex, ttes les probas au-dessus de 0.5)\n",
    "fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "#juste l'aire sous la courbe (1=parfait)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(roc_auc)\n",
    "#OOD detection rate\n",
    "\"\"\" ils font juste nombre de ood trouvés/nb ood mais la manière dont est défini le OOD est peu claire et semble arbitraire\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75 0.6\n"
     ]
    }
   ],
   "source": [
    "#DICE et IoU\n",
    "#exemple\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1]\n",
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "#on ignore les TN car très nombreux (faussent le score), score de similarité --> nb de bonnes préd / toutes les éléments de préd et de ground truth\n",
    "dice=2 * tp / (2 * tp + fp + fn)\n",
    "#idem que dice mais double pas le coef en haut (plus strict dans les résultats)\n",
    "iou=tp / (tp + fp + fn)\n",
    "\n",
    "print(dice,iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.25)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ACE\n",
    "#correct=1 si y_true=y_pred et confid=confiance du modèle\n",
    "#séparation des probas en bins (0-0.1,0.1-0.2...) pour lesquels on calcule le nb de TP --> proba d'être positif dans ce bin\n",
    "#-->moyenne empirique sur les bins de la différence entre proba d'être TP dans la préd et proba d'être positif en vrai \n",
    "#évalue la performance de la prédiction  moyenne à partir d'une partition de l'échantillon\n",
    "def calib_stats(correct, calib_confids):\n",
    "    # calib_confids = np.clip(self.confids, 0, 1)\n",
    "    n_bins = 20\n",
    "    y_true = column_or_1d(correct)\n",
    "    y_prob = column_or_1d(calib_confids)\n",
    "\n",
    "    if y_prob.min() < 0 or y_prob.max() > 1:\n",
    "        raise ValueError(\n",
    "            \"y_prob has values outside [0, 1] and normalize is \" \"set to False.\"\n",
    "        )\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    if len(labels) > 2:\n",
    "        raise ValueError(\n",
    "            \"Only binary classification is supported. \" f\"Provided labels {labels}.\"\n",
    "        )\n",
    "    y_true = label_binarize(y_true, classes=labels)[:, 0]\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0 + 1e-8, n_bins + 1)\n",
    "\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    nonzero = bin_total != 0\n",
    "    num_nonzero = len(nonzero[nonzero == True])\n",
    "    prob_true = bin_true[nonzero] / bin_total[nonzero]\n",
    "    prob_pred = bin_sums[nonzero] / bin_total[nonzero]\n",
    "    prob_total = bin_total[nonzero] / bin_total.sum()\n",
    "\n",
    "    bin_discrepancies = np.abs(prob_true - prob_pred)\n",
    "    return bin_discrepancies, prob_total, num_nonzero\n",
    "\n",
    "\n",
    "def calc_ace(correct, calib_confids):\n",
    "    bin_discrepancies, _, num_nonzero = calib_stats(correct, calib_confids)\n",
    "    return (1 / num_nonzero) * np.sum(bin_discrepancies)\n",
    "\n",
    "#exemple\n",
    "correct= [0, 1, 0, 1, 0, 1, 1, 0, 0, 1]\n",
    "calib_confids= [0.1, 0.9, 0.4, 0.8, 0.2, 0.6, 0.7, 0.3, 0.4, 0.9]\n",
    "calc_ace(correct,calib_confids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8932699455139714)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NCC\n",
    "#CC= à quel point deux images mis en décalé sont similaires (à un décalage près)\n",
    "#normalisedCC=idem mais tient davantage compte de la structure/forme de l'image (mesure indépendante de l'amplitude des valeurs, par exemple une image très lumineuse vs une image très sombre)\n",
    "#littéralement un score de corrélation entre val image 1 et val images 2 mais on ne retire pas la moyenne (ie somme image 1 * image 2/std(1)std(2))\n",
    "#ici plutôt que comparer deux images on compare les cartes d'incertitudes entre la Ground Truth et la Pred\n",
    "def compute_ncc(gt_unc_map: np.array, pred_unc_map: np.array):\n",
    "    \"\"\"\n",
    "    Compute the normalized cross correlation between a ground truth uncertainty and a predicted uncertainty map,\n",
    "    to determine how similar the maps are.\n",
    "    :param gt_unc_map: the ground truth uncertainty map based on the rater variability\n",
    "    :param pred_unc_map: the predicted uncertainty map\n",
    "    :return: float: the normalized cross correlation between gt and predicted uncertainty map\n",
    "    \"\"\"\n",
    "    mu_gt = np.mean(gt_unc_map)\n",
    "    mu_pred = np.mean(pred_unc_map)\n",
    "    sigma_gt = np.std(gt_unc_map, ddof=1)\n",
    "    sigma_pred = np.std(pred_unc_map, ddof=1)\n",
    "    gt_norm = gt_unc_map - mu_gt\n",
    "    pred_norm = pred_unc_map - mu_pred\n",
    "    prod = np.sum(np.multiply(gt_norm, pred_norm))\n",
    "    ncc = (1 / (np.size(gt_unc_map) * sigma_gt * sigma_pred)) * prod\n",
    "    return ncc\n",
    "\n",
    "#exemple\n",
    "gt_unc_map = np.array([\n",
    "    [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "    [0.3, 0.3, 0.5, 0.6, 0.7],\n",
    "    [0.4, 0.4, 0.6, 0.7, 0.8],\n",
    "    [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "])\n",
    "\n",
    "pred_unc_map = np.array([\n",
    "    [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    [0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "    [0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "])\n",
    "\n",
    "compute_ncc(gt_unc_map,pred_unc_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2708333333333333\n",
      "0.0625\n"
     ]
    }
   ],
   "source": [
    "#AURC et EAURC\n",
    "\"\"\"\n",
    "risk=array avec erreurs/loss pour chaque image (proba erreur)\n",
    "confids=confiance dans la préd\n",
    "\"\"\"\n",
    "#tri en fonction de la confiance (croissant)\n",
    "#somme des erreurs parmi val positives pondéré par nb total\n",
    "#AURC bas = bien\n",
    "\n",
    "def rc_curve_stats(\n",
    "    risks: np.array, confids: np.array\n",
    ") -> tuple[list[float], list[float], list[float]]:\n",
    "    coverages = []\n",
    "    selective_risks = []\n",
    "    assert (\n",
    "        len(risks.shape) == 1 and len(confids.shape) == 1 and len(risks) == len(confids)\n",
    "    )\n",
    "\n",
    "    n_samples = len(risks)\n",
    "    idx_sorted = np.argsort(confids)\n",
    "\n",
    "    coverage = n_samples\n",
    "    error_sum = sum(risks[idx_sorted])\n",
    "\n",
    "    coverages.append(coverage / n_samples)\n",
    "    selective_risks.append(error_sum / n_samples)\n",
    "\n",
    "    weights = []\n",
    "\n",
    "    tmp_weight = 0\n",
    "    for i in range(0, len(idx_sorted) - 1):\n",
    "        coverage = coverage - 1\n",
    "        error_sum = error_sum - risks[idx_sorted[i]]\n",
    "        tmp_weight += 1\n",
    "        if i == 0 or confids[idx_sorted[i]] != confids[idx_sorted[i - 1]]:\n",
    "            coverages.append(coverage / n_samples)\n",
    "            selective_risks.append(error_sum / (n_samples - 1 - i))\n",
    "            weights.append(tmp_weight / n_samples)\n",
    "            tmp_weight = 0\n",
    "    return coverages, selective_risks, weights\n",
    "\n",
    "def aurc(risks: np.array, confids: np.array):\n",
    "    _, risks, weights = rc_curve_stats(risks, confids)\n",
    "    return sum(\n",
    "        [(risks[i] + risks[i + 1]) * 0.5 * weights[i] for i in range(len(weights))]\n",
    "    )\n",
    "\n",
    "def eaurc(risks: np.array, confids: np.array):\n",
    "    \"\"\"Compute normalized AURC, i.e. subtract AURC of optimal CSF (given fixed risks).\"\"\"\n",
    "    n = len(risks)\n",
    "    # optimal confidence sorts risk. Asencding here because we start from coverage 1/n\n",
    "    selective_risks = np.sort(risks).cumsum() / np.arange(1, n + 1)\n",
    "    aurc_opt = selective_risks.sum() / n\n",
    "    return aurc(risks, confids) - aurc_opt\n",
    "\n",
    "\n",
    "#exemple\n",
    "confids = np.array([0.9, 0.8, 0.3, 0.6])  \n",
    "\n",
    "risks = np.array([0, 1, 1, 0]) \n",
    "print(aurc(risks,confids))\n",
    "print(eaurc(risks,confids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNC MAP (mais très emmêlé) --> utile ?\n",
    "def get_gt_unc_map(self, image_id):\n",
    "        if self.exp_version.gt_unc_map_loading is None:\n",
    "            n_reference_segs = self.exp_version.n_reference_segs\n",
    "            reference_segs_paths = [\n",
    "                self.ref_seg_dir / f\"{image_id}_{i:02d}{self.exp_version.image_ending}\"\n",
    "                for i in range(n_reference_segs)\n",
    "            ]\n",
    "            reference_segs = []\n",
    "            for reference_seg_path in reference_segs_paths:\n",
    "                reference_seg, _ = load(reference_seg_path)\n",
    "                reference_segs.append(reference_seg)\n",
    "            reference_segs = np.array(reference_segs)\n",
    "            per_pixel_variance = np.var(reference_segs, axis=0)\n",
    "        else:\n",
    "            per_pixel_variance = hydra.utils.instantiate(\n",
    "                self.exp_version.gt_unc_map_loading,\n",
    "                image_id=image_id,\n",
    "                dataloader=self.dataloader,\n",
    "            )\n",
    "        return per_pixel_variance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

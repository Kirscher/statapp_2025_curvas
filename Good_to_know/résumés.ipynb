{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ressources nécessaires pour le projet statapp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Présentation du projet et des principaux concepts (issus des slides de présentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segmentation médicale** : gérer l’incertitude et la variabilité inter-experts. \n",
    "\n",
    "Description : Segmenter les organes est parfois très complexe car les organes varient beaucoup en position et formes. De plus, les experts ne sont pas toujours d’accord pour les segmentations de radiographies. Le but du projet est de garantir de meilleurs diagnostiques en créant un algorithme capable de gérer ces incertitudes. 2 types d’incertitude : aléatoire (données) et épistémique (modèle). But de la quantification des incertitudes : 1) carte d’incertitude pour identifier les zones peu sûres, 2) fournir des prédictions calibrées pour les cliniciens, 3) sécurité accrue en intégrant l’incertitude dans les décisions médicales. \n",
    "\n",
    "<img src=\"/home/onyxia/work/statapp_2025_curvas/Good_to_know/uncertainty.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étapes : \n",
    "1.\tFamiliarisation avec le contexte et les outils. \n",
    "2.\tReproduction de la baseline (entrainement de nnU-Net et analyse des métriques Dice – ECE – CRPS). \n",
    "3.\tAnalyse de l’incertitude via ValUES. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données et code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-\tPour **Statapp** : https://github.com/Kirscher/statapp_2025_curvas \n",
    "-\t**CURVAS** : https://curvas.grand-challenge.org/curvas/ \n",
    "\tCalibration and Uncertainty for multiRater Volume Assessment in multiorgan Segmentation. Addressing interrater variability in DL for medical segmentation involves the development of robust algorithms capable of capturing and quantifying uncertainty, as well as standardizing annotation practices and promoting collaboration among medical experts to reduce variability and improve the reliability of DL-based medical image analysis. The images are CT scans. \n",
    "-\t**Repository CURVAS**: https://github.com/SYCAI-Technologies/curvas-challenge \n",
    "\tContains the training set. \n",
    "-\t**Repository ValUES**: https://github.com/IML-DKFZ/values \n",
    "\tValUES is a framework for systematic validation of uncertainty estimation in semantic segmentation. Can data-related (aleatoric) and model-related (epistemic) uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling.\n",
    "\t<img src=\"/home/onyxia/work/statapp_2025_curvas/Good_to_know/ValUES.png\">\n",
    "    \n",
    "-\t**Repositoy nnU-Net**: https://github.com/MIC-DKFZ/nnUNet \n",
    "\tnnU-Net is a deep learning algorithm for semantic segmentation that automatically adapts to a given image dataset (2D, 3D, RGB image, CT, MRI, …). It will analyze the provided training cases and automatically configure a matching U-Net-based segmentation pipeline. No expertise is required. You can simply train the models and use them. nnU-net relies on supervised learning and uses a lot of data augmentation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles à lire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Isensee, Fabian, et al. nnU-Net : Self-Adapting Framework for U-Net-Based Medical Image Segmentation. arXiv, 2018.\t11 pages https://arxiv.org/abs/1809.10486 \n",
    "- Lambert, Benjamin, 2024, Quantification et caractérisation de l’incertitude de segmentation d’images médicales par des réseaux profonds, PhD thesis, Université Grenoble Alpes, https://theses.hal.science/tel-04673383\t328 pages https://theses.hal.science/tel-04673383 \n",
    "- Kahl, Kim-Celine, et al. ValUES : A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation. arXiv, 2024.\t\t35 pages https://arxiv.org/abs/2401.08501 \n",
    "- Riera i Marín, Meritxell, et al. CURVAS : Calibration and Uncertainty for MultiRater Volume Assessment in Multiorgan Segmentation. Apr. 2024.\t21 pages https://zenodo.org/records/10979642 \n",
    "- Maier-Hein, Lena, Matthias Eisenmann, Annika Reinke, et al., 2018, Why rankings of biomedical image analysis competitions should be interpreted with care, Nature Communications, 9:5217\t13 pages https://www.nature.com/articles/s41467-018-07619-7 \n",
    "- Maier-Hein, Lena, Annika Reinke, et al. Metrics Reloaded : Recommendations for Image Analysis Validation. Nature Methods, vol. 21, no. 2, Feb. 2024, pp. 195–212.\t30 pages https://www.nature.com/articles/s41592-023-02151-z \n",
    "- Ronneberger, Olaf, et al. U-Net : Convolutional Networks for Biomedical Image Segmentation. arXiv, 2015.\t8 pages https://arxiv.org/abs/1505.04597 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning to count biological structures with raters' uncertainty https://zenodo.org/records/8326453 \n",
    "- Multi-rater Prompting for Ambiguous Medical Image Segmentation https://arxiv.org/pdf/2404.07580 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations issues du site web CURVAS (informations sur les métriques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploitation de l’incertitude pour améliorer les modèles :\n",
    "-\t**Out-of-Distribution Detection (OoD)** : Détecter les cas hors distribution pour éviter les erreurs.\n",
    "-\t**Failure Detection (FD)** : Identifier les échecs de segmentation et détecter les prédictions erronées. \n",
    "-\t**Active Learning (AL)** : Sélectionner les échantillons incertains à annoter pour améliorer l’apprentissage. \n",
    "-\t**Calibration** : Ajuster les prédictions du modèles pour qu’elles reflètent correctement les probabilités d’incertitude.\n",
    "-\t**Ambiguity Modelling (AM)** : Modéliser l’incertitude pour quantifier la confiance des prédictions. \n",
    "\n",
    "Images regions: \n",
    "-\t**Foreground consensus areas**: Regions on which the three clinicians have agreed that belongs to the foreground. \n",
    "-\t**Background consensus areas**: Regions on which the three clinicians have agreed that belongs to the background. \n",
    "-\t**Dissensus areas**: Regions in which the three labelers did not agree. \n",
    "\n",
    "Metrics: \n",
    "-\tQuality of the segmentation and uncertainty consensus:\n",
    "**Dice score (DSC)** assesses only the consensus foreground and background areas. Any prediction within the dissensus area will be ignored. False Positives can only occur in the consensus background, False Negatives can only occur in the consensus foreground area. The mean confidence for the consensus background and foreground are CB and CF. The confidence assessment performed in the consensus is **Cseg = [(1 – CB) + CF]/2**. The mean of the three confidence values obtained per each class will be extracted to determine the overall confidence metric for evaluating uncertainty. \n",
    "<img src=\"/home/onyxia/work/statapp_2025_curvas/Good_to_know/DSC.png\">\n",
    " \n",
    "-\tMulti-rater calibration:\n",
    "**Expected Calibration Error (ECE)**: To maintain the multirater information, calibration will be computed for each prediction against each annotation, resulting in three ECE values. We then take the average. \n",
    "<img src=\"/home/onyxia/work/statapp_2025_curvas/Good_to_know/ECE.png\">\n",
    " \n",
    "-\tVolume assessment: \n",
    "The metrics designed above are not relevant for real-world scenarios. To address this, we explore the study of biomarkers such as volume. For this volume assessment, we adopted a different approach. First, we needed a method to retain information from the various annotations. Thus, we defined a gaussian Probabilistic Distribution Function (PDF) using the mean and standard deviation derived from computing the volume the three different annotations. Once the PDF was established, we then defined the corresponding Cumulative Distribution Function (CDF). The predicted volume will be calculated by summing all the probabilistic values for the corresponding class from the probabilistic matrix provided by the participant. This method considers the model's uncertainty and confidence in its predictions when evaluating the volume. For the evaluation of this section the  **Continuous Ranked Probability Score (CRPS)** will be used, see Equation 3. The CRPS measures the average squared difference between a cumulative distribution and a predicted value.\n",
    "<img src=\"/home/onyxia/work/statapp_2025_curvas/Good_to_know/CRPS.png\">\n",
    "<img src=\"/home/onyxia/work/statapp_2025_curvas/Good_to_know/CRPS_2.png\">\n",
    " \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
